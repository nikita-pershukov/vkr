\section{Обзор литературы}
\label{sec:lit-rev}

!!! ПЕРЕПИСАТЬ

Не менее интересны и полезны статьи от IBM [15,16]. Начинаются они со сравнения виртуальных машин и контейнеров, которое было приведено выше. После идет перечисление и детальное рассмотрение каждого из преимуществ использования контейнеров в архитектуре.

По аналогии с сравнением систем CI/CD, стоит обратить внимание на сравнение систем оркестрации контейнеров [17]. Среди рассматриваемых инструментов: Swarm, Kubernetes, Mesos, Cattle. Один из немногих недостатков Kubernetes можно отметить отсутствие ограничений на обращение к диску. Но в тот же момент, среди рассматриваемых систем этим преимуществом обладает только Mesos. В остальном же Kubernetes выигрывает по функциональности с большим отрывом. Если посмотреть на приведенные в публикации графики, то можно увидеть, что есть не один случай, когда Kubernetes выигрывает с большим отрывом от других средств. В других же случаях он на равных с большинством.

Статья [11] освещает сравнение двух популярнейших систем CI/CD - Jenkins и GitLab CI/CD. В ней рассмотрены основные особенности, возможности функционала, и преимущества двух систем. После дается достаточно объективное сравнение этих инструментов, что позволяет выбрать необходимый под создаваемую инфраструктуру.

Если рассмотреть прикладные статьи по тематике контейнеризации, то внимания заслуживает следующий материал [18]. В нем четко сформулированы простые правила написания инструкций для сборки Docker Images. Как аналогия приводится написание кода на языке программирования C или C++. Также лишними не будут листинги с примерами файлов-инструкций.

Еще одна публикация из прикладной сферы [19] освещает использование Docker. В ней рассмотрены самые часто используемые команды для взаимодействия с Docker, пояснение их работы, поведение и анализ происходящей ситуации.

Другая статья [20] рассказывает о влиянии контейнеров на примере Docker на производительность в прикладных задачах. В ней проведены детальные замеры производительности в разных задачах и условиях, что позволяет объективно оценить, насколько данный инструмент подходит для решение необходимого типа задач.

 В дополнение к прикладным статьям, стоит обратить внимание на еще одну [21]. В ней также рассмотрены преимущества контейнеризации, ее особенности. Из ключевых стоит отметить:

простоту,

поддерживаемость,

устойчивость,

воспроизводимость,

удобство,

размер,

прозрачность.

Интересной статьей является еще одна [22]. В ней рассматривается достаточно нестандартное использование Docker для запуска приложений с графическим интерфейсом. Для этого используется дополнительный инструмент - x11docker. Он напрямую связан с графическим сервером - Xorg Windows System Server. Это позволяет выстроить безопасную экосистему, где приложения будут независимы друг от друга и уязвимость в одном из них не позволит получить доступ к другим.

Нельзя обойти стороной рассмотрение официальных лучших практик по контейнеризации от разработчиков самого Docker [23]. Первым и, пожалуй, ключевым они выделяют важность порядка инструкций, потому что если что-то изменяется выше, то все последующие инструкции будут тоже исполнятся заново, что сильно увеличивает время сборки Docker Image.

Еще одна публикация рассматривает обработку больших данных в нескольких облаках посредством контейнеров [24]. Это затрагивает такой аспект как “федерации” - когда кластер может быть разнесен географически, при этом связность данных в нем должна сохраняться. Это достаточно нетривиальная задача, так как при этом данные, поступившие в один филиал, могут еще не успеть дойти до другого, прежде чем они будут запрошены.

В другой статье [25] приводится сравнение вертикального и горизонтального масштабирования. Это давняя известная проблема: вместо наращивания мощности одного инстанса, например, сервера, лучше взять еще один такой же конфигурации. Это позволяет экономить финансы. Но опять же, приложение архитектурно должно быть к этому готово.

Если же рассмотреть промышленное использование в больших масштабах, то стоит обратить внимание на данную книгу [26]. Она рассказывает о “кровавом энтерпрайзе”, что позволяет выявить ряд недостатков в выбранной архитектуре, так как не всегда она подходит под нужды бизнеса.

Для сравнения систем оркестрации не помешает прочитать статью об альтернативе и ее использовании [27]. С одной стороны, она тоже намного мощнее такого инструмента как docker-compose, который подходит для одного микросервиса. Но в сравнении с Kubernetes есть ряд очень ощутимых преимуществ у последнего.

Чтобы лучше понять логику “пакетного менеджера для приложений” - Helm, стоит обратить внимание на статью о его истории и будущем [28]. Как минимум, заслуживает внимание разбор гигантское обновление со второй на третью версию этого инструмента, где отказались от части логики, из-за чего отсутствует обратная совместимость.

Для малого и среднего бизнеса стоит рассмотреть использование продукта компании Flant, который они рекламируют в публикации [29]. Он может сильно упростить процессы CI/CD, то есть упростить жизнь инженерам.

И, как десерт, рассмотрение возможности автомасштабирования в Kubernetes - еще один материал от Flant [30]. Это безумно важно для пилотных проектов, так как если они “выстреливают”, то есть набирают популярность, то нагрузка вырастает в разы, если не на порядки.

Для рассмотрения связки GitLab и Kubernetes отлично подходит статья компании, которая помогает внедрять эти технологии огромному количеству малого и среднего бизнесов \cite{habr:flant:k8s-and-gitlab}. Более того, эта статья заслуживает внимания, так как является выдержкой с выступления на одной из крупнейших конференций в России по высоконагруженным системам - Highload++ 2017. В первую очередь хочется отметить наглядность анимированного изображения, которое позволяет наглядно увидеть разницу между разными инструментами CI/CD.
\Abbrev{CI/CD}{Continuous Integration и Continuous Delivery или Deployment}
\Define{Continuous Integration и Continuous Delivery или Deployment}{этапы непрерывной интеграции разработок и непрерывной доставки кода вплоть до промышленного использования \cite{habr:flant:k8s-and-gitlab}}. Данное изображение дает понять, что:
\begin{itemize}
    \item Git
        \Define{Git}{blablabla}
        вместе с shell
        \Define{Shell}{средство для запуска других программ в ОС GNU/Linux}
        дает несколько окружений и анализ кода.
    \item Добавление Docker позволит улучшить тестирование до тестов без окружения и добавит аспект Stateless
        \Define{Stateless}{blablabla}
        приложения в архитектуру.
    \item Дополнительное использование Kubernetes и Helm позволяет довести тестирование до тестов в "полном" окружении, а архитектуру привести к микросервисной логике.
    \item При пополнении стека с помощью GitLab мы получаем несколько площадок вместо нескольких окружений, а также простое разделение прав доступа. Этого набора уже зачастую предостаточно для покрытия нужд.
    \item Финальный аккорд - GitLab Enterprise, который привносит разные права на окружения, "multi stage approval"
        \Define{Multi stage approval}{blablabla}
        или же "quorum approval"
        \Define{Quorum approval}{blablabla}
        логики.
\end{itemize}
В итоге у компании Flant используется один из самых популярных стеков технологий, за исключением dapp, который на текущий момент переименован в werf, их личная разработка, которая используется для упрощения или улучшения процессов сборки и не только.

В материалах предыдущей статьи есть ссылки на другие статьи, что позволяет глубже погрузиться в тематику. Если посмотреть на обзор другого доклада с RootConf 2017 \cite{habr:flant:k8s-small-projects}, то можно заметить пересечения с вышеупомянутой историей развития архитектуры. Но стоит дополнить тем, что еще не было освещено, а именно рядом сложностей микросервисной архитектуры:
\begin{itemize}
    \item Сбор логов.
    \item Сбор метрик.
    \item Проверка состояния сервисов и их перезапуск в случае проблем.
    \item Автоматическое обнаружение сервисов.
    \item Автоматизация обновления конфигураций компонентов инфраструктуры (при добавлении/удалении новых сущностей сервисов).
    \item Масштабирование.
    \item CI/CD.
    \item Зависимость от выбранного "поставщика решения".
\end{itemize}

По мнению докладчика, все эти сложности можно закрыть с помощью Kubernetes и ряда вспомогательных инструментов.

Далее освещаются базовые аспекты архитектуры Kubernetes, его сущности от Pod до Ingress. Следующий раздел погружает нас в разные архитектуры Kubernetes, в зависимости от нагрузки, требований к отказоустойчивости и других параметров, что еще раз демонстрирует его гибкость как инструмента.

Если изучить еще одну статью [4], которая затрагивает первые практики Continuous Delivery с Docker, то можно раскрыть детальнее первый из этих терминов. Под Continuous Delivery имеется в виду последовательность действий, в результате который код из Git-репозитория сначала собирается, потом тестируется, после чего попадает в промышленное использование и после уходит в архив. Также в статье поднимается вопрос проблемы простоя во время выкатки в промышленное использование новой версии продукта. На текущий момент это решается следующей последовательностью:

старая версия запущена,

в соседнем месте запускается и “прогревается” новая версия,

когда новая версия готова к работе, трафик переключается на нее,

старая версия может быть остановлена.

Не меньшего внимания заслуживает еще одна статья от компании-интегратора Flant уже про базы данных в Kubernetes [5]. Основная проблематика заключается в том, что Kubernetes ориентирован на stateless приложения, то есть приложения без сохранения состояния. А БД - яркий пример stateful приложения, которому жизненно необходимо сохранение своего состояния. В старой архитектуре приложений была следующая логика с СУБД: репликация на двух железных серверах с резервированным питанием диском сетью и всем остальным, включая инженера на дежурной смене. Это позволяло гарантировать, что если что-то или кто-то выйдет из строя, то есть возможность оперативно переключиться или заменить неисправный элемент. В архитектуре же Kubernetes ощутимо другая логика, но она тоже привносит отказоустойчивость:

логика кворума в купе с логикой логикой активного и запасного мастер компонентов, которые управляют кластером,

автоматический переезд сущностей с упавшего сервера на остальные,

возможность декларативно описать логику поведения при недоступности сущности.

Как простое решение с низким показателем критичности в аспекте отказоустойчивости предлагается сущность StatefulSet с одной сущностью Pod, что означает запуск СУБД или другого stateful приложения в одном экземпляре. Этого может быть вполне достаточно для тестовых сред. Чуть более сложная схема - StatefulSet уже с двумя инстансами, между которыми настроена репликация данных с возможностью переключение с активного приложения на запасное. Но оптимальным решением будет рассмотреть приложения с сохранением состояния, которые уже умеют работать в кластере, например Kafka в роли брокера сообщений.

В одной из перечисленных выше статей поднималась проблема мониторинга большого количества сущностей в архитектуре Kubernetes. Но есть статья [6], которая освещает эти моменты. Это также обзор с доклада, в этом случае с RootConf 2018. В его начале рассказывается о ключевых аспектах мониторинга, например, что спидометр показывает скорость и усреднение его редких показателей будут сильно расходится с одометром. Также освещены специфики мониторинга в Kubernetes, основной из которых является совершенно другой масштаб того, что нужно мониторить и с какой скоростью. В статье утверждается, что ключевой выбор для такого мониторинга - Prometheus. Одним из подтверждением этого выбора следуют данные из книги о экосистеме Kubernetes [7]. Далее уже речь заходит об архитектуре самого Prometheus, и о том, какие метрики стоит собирать в Kubernetes. Для наглядного отображение всех агрегированных метрик используется такой инструмент как Grafana.

Кроме вышеперечисленных статей, начинающему стоит обратить внимание на пример или инструкцию развертывания простого проекта в Kubernetes с помощью GitLab CI/CD [10]. Если предварительно посетить и изучить курсы по GitLab, Docker, Kubernetes и Helm, то данный материал будет предельно понятен и поможет начать создание шаблонов для развертывания продуктов в инфраструктуре.

Еще одна проблема - накопление и, как следствие, необходимость умной очистки неиспользуемых Docker Images, освещается в статье от вышеупомянутой компании Flant [12]. Есть два решения данной проблемы: либо использовать фиксированное количество тегов для Docker Images, либо же каким-то образом очищать Docker Images. Во втором случае необходимо выбрать критерии актуальности образа, что также освещено в статье. Ключевой замысел реализован в подборе оптимального количества последних сохраняемых образов для каждой ветки Git-репозитория.


