\section{Kubernetes}
\label{sec:k8s}

Далее необходимо было развернуть кластер для контейнеров. Основным инструментом, решающим эту задачу был выбран Kubernetes.
\Abbrev{K8s}{Kubernetes}
\Define{Kubernetes}{blablabla}
Официальным инструментом для выполнения этой задачи является kubeadm,
\Define{kubeadm}{blablabla}
но он имеет ряд недостатков. Среди них стоит отметить сложность настройки нестандартных конфигураций, не говоря уже о сложности обновления кластера или подключения дополнительных нод. Поэтому был выбран один из самых популярных инструментов -- kubespray.
\Define{kubespray}{blablabla}
Этот инструмент, по своей сути -- YAML-манифесты,
\Define{YAML}{blablabla}
с помощью которого описаны playbook
\Define{playbook}{blablabla}
для Ansible
\Define{Ansible}{blablabla}
-- средства автоматизации по развертыванию инфраструктур. В свою очередь, tasks
\Define{tasks}{blablabla}
и roles
\Define{roles}{blablabla}
в playbook используют kubeadm, но управлять им через данные абстракции в разы проще и удобнее. Также это позволяет иметь готовый артефакт, чтобы повторно развернуть кластер в другом месте или обновить его, внеся небольшие изменения.

Далее будут рассмотрены переменные, определенные в файле для развернутого кластера, отличающиеся от заданных по умолчанию:
\begin{enumerate}
    \item Файл \texttt{inventory.ini}:

        Данный файл кардинально отличается от оригинала, так как тот является лишь примером. В нем указаны в общей группе все инстансы, которые будут использоваться как ноды кластера. Среди них master 
        \Define{master}{blablabla}
        и worker
        \Define{worker}{blablabla}
        ноды, за названием каждой ноды должен быть указан ее IP
        \Abbrev{IP}{blablabla}
        адрес для подключения. Также master ноды должны быть перечислены в группе kube-master. Если etcd
        \Define{etcd}{blablabla}
        будет распологаться на master нодах, то их надо указать в группе etcd, иначе необходимо указать отдельные инстансы в общей группе под хранилище манифестов, и, соотвественно, указать их в группе хранилища. Worker ноды указываются в группе kube-node. Детальнее можно ознакомиться в ПРИЛОЖЕНИИ ТАКОМ-ТО.

    \item Файл \texttt{group\_vars/k8s-cluster/addons.yml} (ПРИЛОЖЕНИЕ ТАКОЕ-ТО):
        \begin{itemize}
            \item \texttt{dashboard\_enabled: true}

                Это позволяет получить базовый dashboard
                \Define{Dashboard}{blablabla}
                с состоянием кластера до момента поднятия полноценного мониторинга.

            \item \texttt{helm\_enabled: true}

                Эта опция устанавливает Helm
                \Define{Helm}{blablabla}
                вместе с кластером Kubernetes.

            \item \texttt{metrics\_server\_enabled: true}

                Включает отдачу метрик.

            \item \texttt{ingress\_nginx\_enabled: false}

                Это значение по умолчанию, но на первых этапах его стоит поменять на true, чтобы иметь в базовой установке кластера Ingress Controller
                \Define{Ingress Controller}{blablabla}
                на базе nginx.
                \Define{nginx}{blablabla}

            \item \texttt{ingress\_nginx\_host\_network: true}

                Данный параметр не будет задействован без предыдущего, но его стоит выставить в значение true, чтобы при включении базового контроллера он был работоспособен за счет обработки трафика с хостовой ноды.

            \item \texttt{ingress\_nginx\_namespace: "ingress-nginx"}

                Здесь указано пространство в кластере, в котором будет находится контроллер. Этот параметр стоит раскомментировать, чтобы четко задать пространство, не предоставляя возможности разместить контроллер в пространстве по умолчанию или же служебном пространстве.

            \item \texttt{ingress\_nginx\_insecure\_port: 80}

                Порт, на который должны приходить HTTP-данные.
                \Abbrev{HTTP}{blablabla}

            \item \texttt{ingress\_nginx\_secure\_port: 443}

                Порт, на который должны приходить HTTPS-данные.
                \Abbrev{HTTPS}{blablabla}

        \end{itemize}
    \item Файл \texttt{group\_vars/k8s-cluster/k8-cluster.yml} (ПРИЛОЖЕНИЕ ТАКОЕ-ТО):
        \begin{itemize}
            \item \texttt{kube\_version: v1.19.6}

                На момент развертывания кластера последняя из стабильных версий kubelet.
                \Define{kubelet}{blablabla}

            \item \texttt{kube\_service\_addresses: 10.10.0.0/16}

                Более широкая по диапазону адресов сеть, нежели предложенная по-умолчанию. Также необходимо отслеживать, чтобы виртуальные сети кластера не пересекались с сетями на хостовых нодах.

            \item \texttt{kube\_pods\_subnet: 10.15.0.0/16}

                Аналогично предыдущему параметру, указана более широкая сеть.

            \item \texttt{cluster\_name: cluster.itsoft}

                Задание имени кластера, что также влияет на внутренние DNS-имена.
                \Abbrev{DNS}{blablabla}

            \item \texttt{podsecuritypolicy\_enabled: true}

                Включение PodSecurityPolicy в кластере, что позволит настроить ограничения работы контейнеров и других сущностей для большей безопасности.
                \Define{PodSecurityPolicy}{blablabla}

            \item \texttt{kubeconfig\_localhost: true}

                Установка служебной утилиты на машину, с которой производится развертывание кластера.

            \item \texttt{kubectl\_localhost: true}

                Установка служебной утилиты для управления кластером на машину, с которой производится развертывание кластера.

        \end{itemize}
    \item Файл \texttt{group\_vars/k8s-cluster/k8-net-calico.yml} (ПРИЛОЖЕНИЕ ТАКОЕ-ТО):
        \begin{itemize}
            \item \texttt{calico\_ip\_auto\_method: “interface=ens3”}

                Опция, позволяющая сетевому плагину для кластера автоматически определить, какую сеть использовать для работы между нодами, на основе указанного сетевого интерфейса.

        \end{itemize}
    \item Файл \texttt{group\_vars/etcd.yml} (ПРИЛОЖЕНИЕ ТАКОЕ-ТО):
        \begin{itemize}
            \item \texttt{etcd\_memory\_limit: 0}

                Такое задание значения параметра снимает ограничения по памяти на хранилище манифестов etcd, что критично для его работы.

        \end{itemize}
    \item Файл \texttt{group\_vars/all/docker.yml} (ПРИЛОЖЕНИЕ ТАКОЕ-ТО):
        \begin{itemize}
            \item \texttt{docker\_storage\_options: -s overlay2}

                Так как на хостах используется свежая версия ядра ОС, то желательно использование более современного драйвера хранения данных для Docker.

        \end{itemize}
\end{enumerate}

После адаптации конфигурационных файлов под задачи и доступные вычислительные ресурсы, необходимо запустить playbook \texttt{cluster.yml}. При дальнейших обновлениях кластера необходимо использовать файл \texttt{upgrade-cluster.yml}.
